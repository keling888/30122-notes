{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M4L2: Record Linkage\n",
    "\n",
    "We saw that under ideal conditions in a database, we can use the primary key to uniquely identify a record.  But in the real world, that's not always the case.\n",
    "\n",
    "Record Linkage or Entity Resolution is the process of identifying records that refer to the same real world entity across multiple data sources.\n",
    "\n",
    "*Deduplication* is a special case of record linkage where you have a single data source and you want to remove duplicate records. (Finding the same record refered to in multiple ways within one data source.)\n",
    "\n",
    "## Example\n",
    "\n",
    "You have a list of restaurants whose owners have given money to a political campaign. You also have a list of restaurants that have been fined by the city. As part of an analysis, you want to see if there is a difference in the average fine amount for businesses that have given money to the campaign versus those that have not.\n",
    "\n",
    "| Business Name | Address | Amount Donated |\n",
    "|---------------|---------|----------------|\n",
    "| Little Coco's | 123 Main St | \\$1000 |\n",
    "| Taqueria Habanero | 901 17th St | \\$250 |\n",
    "| Red Derby | 917 Queen Anne Ave | \\$2000 |\n",
    "| Susana's | 8312 Park Blvd | \\$500 |\n",
    "\n",
    "\n",
    "| ID | Business Name | Address | Fine Amount |\n",
    "|--| --------------|---------|-------------|\n",
    "|1230| Little Coco's Restaurant LLC | 123 Main Street | \\$100 |\n",
    "|2901| Taqueria Habañero | 901 17th Street \\#1 | \\$100 |\n",
    "|3014| IHOP | 917 Queen Ann Avenue | \\$5000 |\n",
    "|3207| Susanna's | 8312 Park Blvd | \\$100 |\n",
    "\n",
    "\n",
    "### Problems\n",
    "\n",
    "There's no shared key between the two tables.  Even with IDs, the campaign finance & restaurant fine systems would not use the same IDs.\n",
    "\n",
    "Furthermore, there are inconsistencies in how the restaurants and addresses are written. It would appear likely that \"Little Coco's\" and \"Little Coco's Restaurant LLC\" are the same restaurant, but trying to match on columns directly will not work.\n",
    "\n",
    "### Record Linkage Steps\n",
    "\n",
    "1. Identify the fields that you want to link on (link keys).   \n",
    "\n",
    "2. Clean & standardize the data in those fields.  (e.g. remove punctuation, convert to lowercase, etc.)\n",
    "\n",
    "3. Score similarity between each link key pair.\n",
    "\n",
    "4. Threshold the scores to determine which pairs are similar enough to be linked.\n",
    "\n",
    "Step 3 requires us to compare every record to every other record.\n",
    "\n",
    "Basic form:\n",
    "\n",
    "```python\n",
    "matches = []\n",
    "\n",
    "for item1 in dataset1:\n",
    "    for item2 in dataset2:\n",
    "        # thresholds were chosen arbitrarily\n",
    "        if item_similarity(item1.name, item2.name) > 0.8 and items_similarity(item1.address, item2.address) > 0.9:\n",
    "            matches.append((item1, item2))\n",
    "```\n",
    "\n",
    "Note: `item_similarity` is a function you'd need to define, however you want to compare the strings.\n",
    "\n",
    "### Aside: `itertools.product`\n",
    "\n",
    "When you have a nested loop, you can use `itertools.product` to make it a bit more concise.  \n",
    "\n",
    "`itertools.product` takes two iterables and returns an iterable of tuples of the items from each iterable.  (In relational terms, the cross product of the two iterables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "list1 = [\"a\", \"b\", \"c\"]\n",
    "list2 = [1, 2, 3]\n",
    "for item1, item2 in itertools.product(list1, list2):\n",
    "    print(item1, item2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import itertools\n",
    "\n",
    "matches = []\n",
    "for item1, item2 in itertools.product(dataset1, dataset2):\n",
    "    if item_similarity(item1.name, item2.name) > 0.8 and item_similarity(item1.address, item2.address) > 0.9:\n",
    "        matches.append((item1, item2))\n",
    "```\n",
    "\n",
    "### Efficiency\n",
    "\n",
    "Without clever tricks, this algorithm is `O(n*m)` where `n` is the number of items in `dataset1` and `m` is the number of items in `dataset2`.\n",
    "\n",
    "This is effectively `O(n^2)` because `n` and `m` are usually similar enough.\n",
    "\n",
    "That means when you have 1000 items in each dataset, you're doing 1,000,000 calls to your `item_similarity()` function.\n",
    "\n",
    "But `item_similarity()` is fast right??\n",
    "\n",
    "## String Similarity\n",
    "\n",
    "There are a lot of ways to compare strings.\n",
    "\n",
    "### Hamming Distance\n",
    "\n",
    "Computes the number of characters that differ between two strings of equal length.\n",
    "\n",
    "```python\n",
    "def hamming_distance(s1, s2):\n",
    "    # ensure length of s1 >= s2 using an in-place swap\n",
    "    if len(s2) > len(s1):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    # distance is difference in length + differing chars\n",
    "    distance = len(s1) - len(s2)\n",
    "    for i, c in enumerate(s2):\n",
    "        if c != s1[i]:\n",
    "            distance += 1\n",
    "\n",
    "    return distance\n",
    "```\n",
    "\n",
    "This is a very simple implementation, but as we'll see it isn't incredibly useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import hamming_distance\n",
    "\n",
    "print(hamming_distance(\"Taqueria Habañero\", \"Taqueria Habanero\"))\n",
    "1\n",
    "print(hamming_distance(\"Susana's\", \"Susanna's\"))\n",
    "4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these are one character off, but the Hamming distance is 1 and 4, respectively.\n",
    "\n",
    "Hamming distance only handles replacements, not insertions or deletions. Since it is not normalized to the length of the string, it works best on strings of the same length.\n",
    "\n",
    "### Levenshtein Distance\n",
    "\n",
    "Levenshtein distance is a more general version of Hamming distance. It allows for insertions, deletions, and replacements.\n",
    "\n",
    "The bad news is that the algorithm is O(n*m) where n and m are the lengths of the strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import levenshtein_distance\n",
    "\n",
    "print(levenshtein_distance(\"Taqueria Habañero\", \"Taqueria Habanero\"))\n",
    "1\n",
    "print(levenshtein_distance(\"Susana's\", \"Susanna's\"))\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtein distance is also known as edit distance.\n",
    "\n",
    "#### Damerau-Levenshtein Distance\n",
    "\n",
    "Adjustment to Levenshtein distance that allows for transpositions to be counted as a single edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import damerau_levenshtein_distance\n",
    "\n",
    "print(levenshtein_distance(\"Fish\", \"Fsih\"))\n",
    "2\n",
    "print(damerau_levenshtein_distance(\"Fish\", \"Fsih\"))\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we still have the issue that strings of different lengths are not comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(damerau_levenshtein_distance(\"Little Coco's\", \"Little Coco's Restaurant LLC\"))\n",
    "15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'd be nice if these were somehow normalized based on length.\n",
    "\n",
    "### Jaro Similarity\n",
    "\n",
    "The Jaro distance is a string similarity measure, which measures the edit distance between two sequences.\n",
    "\n",
    "It **normalizes** the distance by the length of the strings so that the result is between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import jaro_similarity\n",
    "\n",
    "print(jaro_similarity(\"Taqueria Habañero\", \"Taqueria Habanero\"))\n",
    "# 0.9608\n",
    "\n",
    "print(jaro_similarity(\"Susana's\", \"Susanna's\"))\n",
    "# 0.9630\n",
    "\n",
    "print(jaro_similarity(\"Little Coco's\", \"Little Coco's Restaurant LLC\"))\n",
    "# 0.8214\n",
    "\n",
    "print(jaro_similarity(\"Little Coco's\", \"Susanna's\"))\n",
    "# 0.4587"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaro-Winkler \n",
    "And the Jaro-Winkler similarity is a modification of the Jaro distance that gives more favorable ratings to strings that match from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import jaro_winkler_similarity\n",
    "\n",
    "print(jaro_winkler_similarity(\"Taqueria Habañero\", \"Taqueria Habanero\"))\n",
    "# 0.9707\n",
    "\n",
    "print(jaro_winkler_similarity(\"Susana's\", \"Susanna's\"))\n",
    "# 0.9778\n",
    "\n",
    "print(jaro_winkler_similarity(\"Little Coco's\", \"Little Coco's Restaurant LLC\"))\n",
    "# 0.8929\n",
    "\n",
    "print(jaro_winkler_similarity(\"Little Coco's\", \"Susanna's\"))\n",
    "# 0.4587"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our matches got a boost from Jaro-Winkler similarity.\n",
    "\n",
    "If the beginning of a string is more important than the end, this makes Jaro-Winkler a good choice.\n",
    "\n",
    "### String Similarity: Conclusion\n",
    "\n",
    "Hamming, Levenshtein, and Damerau-Levenshtein can all be useful in different situations.\n",
    "\n",
    "Jaro or Jaro-Winkler make a good general purpose choice.\n",
    "\n",
    "## Phonetic Encoding\n",
    "\n",
    "An alternative approach is to shorten the string by encoding it in different ways.\n",
    "\n",
    "### Match Rating Approach\n",
    "\n",
    "A generic version of this is known as the Match Rating Approach.  This converts each string into a string of characters that are similar to the original string based upon phonetic similarity.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import match_rating_codex, match_rating_comparison\n",
    "\n",
    "print(match_rating_codex(\"Taqueria Habañero\"))\n",
    "# TQRBÑR\n",
    "print(match_rating_codex(\"Susana's\"))\n",
    "# SNSS\n",
    "print(match_rating_comparison(\"Taqueria Habañero\", \"Taqueria Habanero\"))\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soundex\n",
    "\n",
    "Soundex is a phonetic algorithm for indexing names by sound, as pronounced in English. The goal is for homophones to be encoded to the same representation so that they can be matched despite minor differences in spelling.\n",
    "\n",
    "`soundex('Ann') == soundex('Anne') == 'A500'`\n",
    "\n",
    "`soundex('Rupert') == soundex('Robert') == 'R163'`\n",
    "\n",
    "\n",
    "### Metaphone\n",
    "\n",
    "Metaphone is more complex than Soundex, but it's also more accurate.\n",
    "\n",
    "`metaphone('Klumpz') == metaphone('Clumps') == 'KLMPS'.`\n",
    "\n",
    "Metaphone is particularly good at handling soundalikes like C/K and PH/F.\n",
    "\n",
    "### And So On...\n",
    "\n",
    "* NYSIIS\n",
    "* Double Metaphone\n",
    "* Triple Metaphone\n",
    "* Caverphone - New Zealand Pronunciation\n",
    "\n",
    "## How Similar is Similar Enough?\n",
    "\n",
    "How do you decide what is similar enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from jellyfish import jaro_winkler_similarity\n",
    "\n",
    "all_words = open(\"shakespeare.txt\").read().split()\n",
    "words = all_words[:2000]\n",
    "\n",
    "def graph_jw(list1, list2):\n",
    "    all_similarities = []\n",
    "    for word1, word2 in itertools.product(list1, list2):\n",
    "        jws = jaro_winkler_similarity(word1, word2)\n",
    "        if jws > 0:\n",
    "            all_similarities.append(jws)\n",
    "    # graph of all non-zero similarities\n",
    "    plt.hist(all_similarities, bins=100)\n",
    "\n",
    "graph_jw(words, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a histogram of the Jaro-Winkler similarity scores for all pairs of words in the first 2000 words of Shakespeare's works. \n",
    "\n",
    "The vast majority of words fall between 0.4 and 0.7 or so, you'll want to select a threshold that makes sense for your data.\n",
    "\n",
    "Graphing output like this can be useful in developing some intuition about your particular data set.\n",
    "\n",
    "(**See Jaro-Winkler PDF**)\n",
    "\n",
    "## Record Linkage\n",
    "\n",
    "With string similarity in our toolbox, we can now start to think about how to use it to link records.\n",
    "\n",
    "### Record Linkage Steps Revisited\n",
    "\n",
    "1. Identify the fields that you want to link on (link keys).   \n",
    "\n",
    "2. Clean & standardize the data in those fields.  (e.g. remove punctuation, convert to lowercase, etc.)\n",
    "\n",
    "3. Score similarity between each link key pair.\n",
    "\n",
    "4. Threshold the scores to determine which pairs are similar enough to be linked.\n",
    "\n",
    "We've now covered steps 1-3.  Let's look at step 4.  How do we decide what is similar enough?\n",
    "\n",
    "### Rules Based Approaches\n",
    "\n",
    "One approach is to use rules based on the data.  For example, if you're linking on names, you might say that if the Jaro-Winkler similarity is greater than 0.9, then the records are linked.\n",
    "\n",
    "This requires making arbitrary decisions about what is similar enough.  This is often done by running with different thresholds and looking at the results until one is found that seems reasonable.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import jaro_winkler_similarity\n",
    "\n",
    "def link_records(record1, record2):\n",
    "    return (jaro_winkler_similarity(record1['name'], record2['name']) > 0.9 and\n",
    "            jaro_winkler_similarity(record1['address'], record2['address']) > 0.9 and\n",
    "            record1['city'] == record2['city'] and\n",
    "            record1['state'] == record2['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Approaches\n",
    "\n",
    "A more principled approach is to use a probabilistic model to determine the likelihood that two records are linked.\n",
    "\n",
    "This is a bit more complicated, but it has the advantage that it can be used to determine the optimal threshold for a specific application.\n",
    "\n",
    "For example, if you are dealing with linking medical records, you might want to be conservative in what you link to avoid accidentally linking two patients who are not the same person.  In this case, you would want to configure your model to have a low false positive rate.\n",
    "\n",
    "On the other hand, if you are doing an analysis across decennial census records, you might want to be more aggressive in linking records to get a more complete picture of the population.  In this case, you would want to configure your model to have a low false negative rate.\n",
    "\n",
    "Probabilistic approaches require already labeled data to train the model. This is often done by having a human look at a sample of the records and label them as linked or not linked.  This data will form a baseline that the model's predictions can be compared against.\n",
    "\n",
    "### Probabilistic Approaches: Example\n",
    "\n",
    "We have two lists of people that we'd like to link: `A` and `B`.\n",
    "\n",
    "We take a sample of the data `A_sample` and `B_sample` and label the pairs (`A_sample X B_sample`) as linked or not linked.  Call the matched pairs `M` and the unmatched pairs `U`.\n",
    "\n",
    "We then define a scoring function for each link key.  For example, we might have a scoring function for names that returns \"good match\", \"intermediate match\", or \"no match\".  We'll call this `name_scoring_function`.  We could also have a similar function for address, year of birth, etc.\n",
    "\n",
    "If we get two records `a` and `b` from `A` and `B` respectively, we'd use our scoring function:\n",
    "\n",
    "```python\n",
    "name_score = scoring_function(a[\"name\"], b[\"name\"])\n",
    "# score is either \"good match\", \"intermediate match\", or \"no match\"\n",
    "```\n",
    "\n",
    "Let's say we get \"intermediate match\".\n",
    "\n",
    "We need to know the probability of getting such a score among the matches and among the non-matches.  We can compute this from the labeled data.\n",
    "\n",
    "We determine the probability of getting such a value among the matches in `M`, `P(name has \"intermediate\" | M)`, by looking at the fraction of matches that have such a value for the field name.\n",
    "\n",
    "Similarly we determine the probability for getting such a value among the non-matches, `P(first name has \"intermediate\" | U)`.\n",
    "\n",
    "We compute such probabilities corresponding to address as well.\n",
    "\n",
    "Suppose the result of `address_scoring_function(a, b)` is `\"good match\"`.\n",
    "We then compute `P(address has \"good match\" | M)` and `P(address has \"good match\" | U)`.\n",
    "\n",
    "Now we are ready to find the ratio of the probabilities, assuming independence between first name and year of birth.\n",
    "\n",
    "```R = ( P(name has \"intermediate | M) * P(address has \"good match\" | M) ) / ( P(name has \"intermediate | U) * P(address has \"good match\" | U )```\n",
    "\n",
    "Based again on training data we determine thresholds T1 and T2, such that when the score is above T1 we assign (a, b) as a match, and if below T2 as a non-match.  In between them they are sent for a manual clerical review.\n",
    "\n",
    "### Machine Learning Approaches\n",
    "\n",
    "Another approach is to use machine learning to determine the optimal threshold.  This is particularly useful when there are a large number of fields and you don't have a clear idea of how they help in record linkage.  It's beyond the scope of what we can cover here, but relatively easy to implement using a library like scikit-learn.\n",
    "\n",
    "<https://scikit-learn.org/stable/index.html>\n",
    "\n",
    "### Blocking\n",
    "\n",
    "Sometimes there are fields that we are confident are very important for a match.\n",
    "\n",
    "Perhaps 99.9% of matches have the correct state. If when comparing two records we find that they have different states, we can be confident that they are not a match and avoid doing the rest of the work.\n",
    "\n",
    "Let's say we have a million records in each dataset, no matter how fast our algorithm is, we're looking at a trillion comparisons.\n",
    "\n",
    "If we first reduce the records by state, into 50 groups averaging 200,000 records each, \"only\" 20 billion comparisons need to be done.\n",
    "\n",
    "That's a 98% reduction in the number of comparisons.\n",
    "\n",
    "You can get clever by creating a blocking key, which is a string that is used to group records together.\n",
    "\n",
    "For example, you could use the first letter of a person's last name and their zip code to group people in a dataset so you're only comparing records\n",
    "that have a fairly high likelihood of matching.\n",
    "\n",
    "### Privacy Issues\n",
    "\n",
    "Record linkage can be used to de-anonymize data.\n",
    "\n",
    "E.g., a Harvard researcher was able to identify 40% of anonymous donors in a DNA study because the data included zip codes, dates of birth, and genders, and the researcher combined these with voter rolls, etc.\n",
    "\n",
    "When linking records, it's important to consider the privacy implications of the data you're linking, particularly when individuals are involved.\n",
    "\n",
    "As always, practice responsible disclosure, if you uncover a privacy issue, report it to the data owner with suggestions on how to remedy it. Careless de-anonymization can have serious consequences for vulnerable individuals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
